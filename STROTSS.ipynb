{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STROTSS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ak9250/STROTSS/blob/master/STROTSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Mlrjhm4AFoaA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nkolkin13/STROTSS.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IilvAc4BF3Mu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd STROTSS/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z4SSYN5vHTl8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget url to image -O content_im.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vkpKfVDuUM8F"
      },
      "cell_type": "markdown",
      "source": [
        "make any edits to styletransfer.py (Optional)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Oz8OonTZUNYs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%writefile styleTransfer.py\n",
        "import time\n",
        "import math\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from imageio import imread, imwrite\n",
        "\n",
        "from   st_helper import *\n",
        "import utils\n",
        "from   utils import *\n",
        "\n",
        "def run_st(content_path, style_path, content_weight, max_scl, coords, use_guidance,regions, output_path='./output.png'):\n",
        "\n",
        "    smll_sz = 64\n",
        "    \n",
        "    start = time.time()\n",
        "\n",
        "    content_im_big = utils.to_device(Variable(load_path_for_pytorch(content_path,512,force_scale=True).unsqueeze(0)))\n",
        "\n",
        "    for scl in range(1,max_scl):\n",
        "\n",
        "        long_side = smll_sz*(2**(scl-1))\n",
        "        lr = 2e-3\n",
        "\n",
        "        ### Load Style and Content Image ###\n",
        "        content_im = utils.to_device(Variable(load_path_for_pytorch(content_path,long_side,force_scale=True).unsqueeze(0)))\n",
        "        content_im_mean = utils.to_device(Variable(load_path_for_pytorch(style_path,long_side,force_scale=True).unsqueeze(0))).mean(2,keepdim=True).mean(3,keepdim=True)\n",
        "        \n",
        "        ### Compute bottom level of laplaccian pyramid for content image at current scale ###\n",
        "        lap = content_im.clone()-F.upsample(F.upsample(content_im,(content_im.size(2)//2,content_im.size(3)//2),mode='bilinear'),(content_im.size(2),content_im.size(3)),mode='bilinear')\n",
        "        nz = torch.normal(lap*0.,0.1)\n",
        "\n",
        "\n",
        "        canvas = F.upsample(torch.clamp(lap,-0.5,0.5),(content_im_big.size(2),content_im_big.size(3)),mode='bilinear')[0].data.cpu().numpy().transpose(1,2,0)\n",
        "\n",
        "        if scl == 1:\n",
        "            canvas = F.upsample(content_im,(content_im.size(2)//2,content_im.size(3)//2),mode='bilinear')[0].data.cpu().numpy().transpose(1,2,0)\n",
        "\n",
        "        ### Initialize by zeroing out all but highest and lowest levels of Laplaccian Pyramid ###\n",
        "        if scl == 1:\n",
        "            if 1:\n",
        "                stylized_im = Variable(content_im_mean+lap)\n",
        "            else:\n",
        "                stylized_im = Variable(content_im.data)\n",
        "\n",
        "        ### Otherwise bilinearly upsample previous scales output and add back bottom level of Laplaccian pyramid for current scale of content image ###\n",
        "        if scl > 1 and scl < max_scl-1:\n",
        "            stylized_im = F.upsample(stylized_im.clone(),(content_im.size(2),content_im.size(3)),mode='bilinear')+lap\n",
        "\n",
        "        if scl > 3:\n",
        "            stylized_im = F.upsample(stylized_im.clone(),(content_im.size(2),content_im.size(3)),mode='bilinear')\n",
        "            lr = 1e-3\n",
        "\n",
        "        ### Style Transfer at this scale ###\n",
        "        stylized_im, final_loss = style_transfer(stylized_im, content_im, style_path, output_path, scl, long_side, 0., use_guidance=use_guidance, coords=coords, content_weight=content_weight, lr=lr, regions=regions)\n",
        "\n",
        "        canvas = F.upsample(torch.clamp(stylized_im,-0.5,0.5),(content_im.size(2),content_im.size(3)),mode='bilinear')[0].data.cpu().numpy().transpose(1,2,0)\n",
        "        \n",
        "        ### Decrease Content Weight for next scale ###\n",
        "        content_weight = content_weight/2.0\n",
        "\n",
        "    print(\"Finished in: \", int(time.time()-start), 'Seconds')\n",
        "    print('Final Loss:', final_loss)\n",
        "\n",
        "    canvas = torch.clamp(stylized_im[0],-0.5,0.5).data.cpu().numpy().transpose(1,2,0)\n",
        "    imwrite(output_path,canvas)\n",
        "    return final_loss , stylized_im\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    ### Parse Command Line Arguments ###\n",
        "    content_path = sys.argv[1]\n",
        "    style_path = sys.argv[2]\n",
        "    content_weight = float(sys.argv[3])*16.0\n",
        "    max_scl = 5\n",
        "\n",
        "    use_guidance_region = '-gr' in sys.argv\n",
        "    use_guidance_points = False\n",
        "    use_gpu = not ('-cpu' in sys.argv)\n",
        "    utils.use_gpu = use_gpu\n",
        "\n",
        "\n",
        "    paths = glob(style_path+'*')\n",
        "    losses = []\n",
        "    ims = []\n",
        "\n",
        "\n",
        "    ### Preprocess User Guidance if Required ###\n",
        "    coords=0.\n",
        "    if use_guidance_region:\n",
        "        i = sys.argv.index('-gr')\n",
        "        regions = utils.extract_regions(sys.argv[i+1],sys.argv[i+2])\n",
        "    else:\n",
        "        try:\n",
        "            regions = [[imread(content_path)[:,:,0]*0.+1.], [imread(style_path)[:,:,0]*0.+1.]]\n",
        "        except:\n",
        "            regions = [[imread(content_path)[:,:]*0.+1.], [imread(style_path)[:,:]*0.+1.]]\n",
        "\n",
        "    ### Style Transfer and save output ###\n",
        "    loss,canvas = run_st(content_path,style_path,content_weight,max_scl,coords,use_guidance_points,regions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AbWxEXjKF9A1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 styleTransfer.py /content/STROTSS/content_im.jpg /content/STROTSS/style_im.jpg 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e4qNnywRGIhT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 styleTransfer.py /content/STROTSS/content_im.jpg /content/STROTSS/style_im.jpg 0.5 -gr /content/STROTSS/content_guidance.jpg /content/STROTSS/style_guidance.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oDlVrex2Mnmi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}